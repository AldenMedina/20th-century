{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620ab510-490c-4ad9-9a36-ae25ca34fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8da9b9c8-3d2f-4daf-9543-72ebe6f084d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mspacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m displacy\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53cfab20-ad6e-4d86-a07e-2887e0cc152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.5-cp312-cp312-macosx_10_13_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-macosx_10_13_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-macosx_10_13_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.15.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/alden/miniconda3/lib/python3.12/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /Users/alden/miniconda3/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/alden/miniconda3/lib/python3.12/site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/alden/miniconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/alden/miniconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alden/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alden/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alden/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alden/miniconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/alden/miniconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/alden/miniconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.8.5-cp312-cp312-macosx_10_13_x86_64.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-macosx_10_13_x86_64.whl (42 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-macosx_10_13_x86_64.whl (27 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-macosx_10_9_x86_64.whl (133 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-macosx_10_13_x86_64.whl (636 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.7/636.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading thinc-8.3.6-cp312-cp312-macosx_10_13_x86_64.whl (890 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading typer-0.15.3-py3-none-any.whl (45 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.3.0-cp312-cp312-macosx_10_13_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-macosx_10_13_x86_64.whl (190 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-macosx_10_13_x86_64.whl (38 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, shellingham, numpy, murmurhash, marisa-trie, cloudpathlib, catalogue, srsly, smart-open, preshed, language-data, blis, typer, langcodes, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 numpy-2.2.5 preshed-3.0.9 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-0.15.3 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1126ae-14bb-413f-872c-cc0bd34c89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01239986-75c8-46d2-8ba4-1636eb9bfd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "652599af-f7cb-4e16-bbf3-e4890336cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy English model\n",
    "import spacy\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the 20th-century article\n",
    "with open(\"20th_century_wiki.txt\", \"r\", errors=\"ignore\") as file:\n",
    "    data = file.read().replace('\\n', ' ')\n",
    "\n",
    "# Apply NER to the text\n",
    "doc = NER(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbce60bc-0f7b-42a0-a404-622b304dbf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Timeline of the 20th century - Wikipedia    ...</td>\n",
       "      <td>[the 20th century, Search            Search   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.9 1909           2 1910s     Toggle 1910s su...</td>\n",
       "      <td>[1910s, 2.1, 2.3 1912         2.4 1913        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Further reading         15 References         ...</td>\n",
       "      <td>[References                   Toggle, the 20th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color (beta)AutomaticLightDarkThis page is alw...</td>\n",
       "      <td>[Color]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From Wikipedia, the free encyclopedia     hide...</td>\n",
       "      <td>[Wikipedia]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0    Timeline of the 20th century - Wikipedia    ...   \n",
       "1  1.9 1909           2 1910s     Toggle 1910s su...   \n",
       "2  Further reading         15 References         ...   \n",
       "3  Color (beta)AutomaticLightDarkThis page is alw...   \n",
       "4  From Wikipedia, the free encyclopedia     hide...   \n",
       "\n",
       "                                            entities  \n",
       "0  [the 20th century, Search            Search   ...  \n",
       "1  [1910s, 2.1, 2.3 1912         2.4 1913        ...  \n",
       "2  [References                   Toggle, the 20th...  \n",
       "3                                            [Color]  \n",
       "4                                        [Wikipedia]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentences_data = []\n",
    "\n",
    "for sent in doc.sents:\n",
    "    entities = [ent.text for ent in sent.ents]\n",
    "    sentences_data.append({\"sentence\": sent.text, \"entities\": entities})\n",
    "\n",
    "df_sentences = pd.DataFrame(sentences_data)\n",
    "df_sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df8c14ba-2947-43bb-abac-9d6a6c5e7309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "      <th>country_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>January 22: Edward VII became King of England ...</td>\n",
       "      <td>[January 22, Edward VII, India, Queen Victoria's]</td>\n",
       "      <td>[India]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>June: Emily Hobhouse reports on the poor condi...</td>\n",
       "      <td>[June, Emily Hobhouse, 45, British, Boer, Sout...</td>\n",
       "      <td>[South Africa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>September 7: The Eight-Nation Alliance defeats...</td>\n",
       "      <td>[September 7, Eight, the Boxer Rebellion, China]</td>\n",
       "      <td>[China]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Venezuelan crisis of 1902–1903, in which Brita...</td>\n",
       "      <td>[Venezuelan, 1902–1903, Britain, Germany, Ital...</td>\n",
       "      <td>[Germany, Italy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>In Russia the Bolsheviks and the Mensheviks fo...</td>\n",
       "      <td>[Russia, Bolsheviks, Mensheviks, the Russian S...</td>\n",
       "      <td>[Russia]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "17  January 22: Edward VII became King of England ...   \n",
       "19  June: Emily Hobhouse reports on the poor condi...   \n",
       "21  September 7: The Eight-Nation Alliance defeats...   \n",
       "30  Venezuelan crisis of 1902–1903, in which Brita...   \n",
       "34  In Russia the Bolsheviks and the Mensheviks fo...   \n",
       "\n",
       "                                             entities  country_entities  \n",
       "17  [January 22, Edward VII, India, Queen Victoria's]           [India]  \n",
       "19  [June, Emily Hobhouse, 45, British, Boer, Sout...    [South Africa]  \n",
       "21   [September 7, Eight, the Boxer Rebellion, China]           [China]  \n",
       "30  [Venezuelan, 1902–1903, Britain, Germany, Ital...  [Germany, Italy]  \n",
       "34  [Russia, Bolsheviks, Mensheviks, the Russian S...          [Russia]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example country list (replace with your own list or import from CSV)\n",
    "countries = [\n",
    "    \"United States\", \"Germany\", \"China\", \"Japan\", \"Russia\", \"France\",\n",
    "    \"United Kingdom\", \"Canada\", \"Mexico\", \"Italy\", \"India\", \"Brazil\",\n",
    "    \"Argentina\", \"South Africa\", \"Turkey\", \"Iran\", \"Spain\", \"Australia\",\n",
    "    \"Poland\", \"Iraq\"\n",
    "]\n",
    "\n",
    "# Filter entities by country list\n",
    "def filter_countries(entity_list, country_list):\n",
    "    return [ent for ent in entity_list if ent in country_list]\n",
    "\n",
    "df_sentences[\"country_entities\"] = df_sentences[\"entities\"].apply(lambda ents: filter_countries(ents, countries))\n",
    "df_sentences_filtered = df_sentences[df_sentences[\"country_entities\"].map(len) > 0]\n",
    "df_sentences_filtered.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f5553f-e15f-4a68-b60a-0954a51e7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = []\n",
    "\n",
    "# Sliding window of 5 sentences\n",
    "for i in range(df_sentences_filtered.index[-1]):\n",
    "    end_i = min(i + 5, df_sentences_filtered.index[-1])\n",
    "    window_countries = sum(df_sentences_filtered.loc[i:end_i, \"country_entities\"], [])\n",
    "    unique_countries = [window_countries[i] for i in range(len(window_countries)) if i == 0 or window_countries[i] != window_countries[i-1]]\n",
    "    \n",
    "    if len(unique_countries) > 1:\n",
    "        for idx, a in enumerate(unique_countries[:-1]):\n",
    "            b = unique_countries[idx + 1]\n",
    "            relationships.append({\"source\": a, \"target\": b})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095e5278-de89-4745-bbfb-5e31da7ee560",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'np'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m relationship_df = pd.DataFrame(relationships)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Sort so A-B and B-A are counted as the same\u001b[39;00m\n\u001b[32m      4\u001b[39m relationship_df = pd.DataFrame(\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     pd.np.sort(relationship_df.values, axis=\u001b[32m1\u001b[39m),\n\u001b[32m      6\u001b[39m     columns=[\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Count occurrences\u001b[39;00m\n\u001b[32m     10\u001b[39m relationship_df[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m1\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'pandas' has no attribute 'np'"
     ]
    }
   ],
   "source": [
    "relationship_df = pd.DataFrame(relationships)\n",
    "\n",
    "# Sort so A-B and B-A are counted as the same\n",
    "relationship_df = pd.DataFrame(\n",
    "    pd.np.sort(relationship_df.values, axis=1),\n",
    "    columns=[\"source\", \"target\"]\n",
    ")\n",
    "\n",
    "# Count occurrences\n",
    "relationship_df[\"value\"] = 1\n",
    "relationship_df = relationship_df.groupby([\"source\", \"target\"], as_index=False).sum()\n",
    "relationship_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f464a5d7-907c-47d7-953e-03df77a05258",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df.to_csv(\"20th_century_country_relationships.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b43b1140-c586-42a6-a441-ccf9cda40ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/xr0wqnt55l9gzqjgx49c_h8r0000gp/T/ipykernel_15336/690278295.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sentences_filtered[\"country_entities\"] = df_sentences_filtered[\"country_entities\"].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source  target  value\n",
      "0  Africa   China      5\n",
      "1  Africa    Iran      1\n",
      "2  Africa   Japan      3\n",
      "3  Africa  Poland      1\n",
      "4  Africa  Russia      3\n"
     ]
    }
   ],
   "source": [
    "# === Install & Import ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Load SpaCy English model (only needs to be done once)\n",
    "# !python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# === Load Text ===\n",
    "with open(\"20th_century_wiki.txt\", \"r\", errors=\"ignore\") as file:\n",
    "    text = file.read().replace(\"\\n\", \" \")\n",
    "\n",
    "# === Create NER Object ===\n",
    "doc = nlp(text)\n",
    "\n",
    "# === Optional: Visualize slice ===\n",
    "# displacy.render(doc[300:1000], style=\"ent\", jupyter=True)\n",
    "\n",
    "# === Split Into Sentences and Capture Entities ===\n",
    "sentences_data = []\n",
    "for sent in doc.sents:\n",
    "    entity_list = [ent.text for ent in sent.ents]\n",
    "    sentences_data.append({\"sentence\": sent.text, \"entities\": entity_list})\n",
    "\n",
    "df_sentences = pd.DataFrame(sentences_data)\n",
    "\n",
    "# === Load Country List ===\n",
    "# Replace with your list of countries, or load from CSV if you saved it\n",
    "countries = [\n",
    "    \"United States\", \"China\", \"United Kingdom\", \"Germany\", \"France\", \"Japan\", \"Russia\",\n",
    "    \"India\", \"Italy\", \"Canada\", \"Australia\", \"Brazil\", \"Spain\", \"Poland\", \"South Africa\",\n",
    "    \"Mexico\", \"Turkey\", \"Argentina\", \"Iran\", \"Iraq\"\n",
    "]\n",
    "\n",
    "# Create aliases for matching — use just last word for SpaCy match\n",
    "country_aliases = [country.split()[-1] for country in countries]\n",
    "\n",
    "# === Filter Entities to Match Country List ===\n",
    "def filter_entity(ent_list):\n",
    "    return [ent for ent in ent_list if ent in country_aliases]\n",
    "\n",
    "df_sentences[\"country_entities\"] = df_sentences[\"entities\"].apply(filter_entity)\n",
    "\n",
    "# === Filter Out Sentences With No Country Entities ===\n",
    "df_sentences_filtered = df_sentences[df_sentences[\"country_entities\"].map(len) > 0]\n",
    "\n",
    "# === Simplify Names to Last Word (e.g., 'United States' -> 'States') ===\n",
    "df_sentences_filtered[\"country_entities\"] = df_sentences_filtered[\"country_entities\"].apply(\n",
    "    lambda x: [ent.split()[-1] for ent in x]\n",
    ")\n",
    "\n",
    "# === Create Relationships ===\n",
    "relationships = []\n",
    "for i in range(df_sentences_filtered.index[-1]):\n",
    "    end_i = min(i + 5, df_sentences_filtered.index[-1])\n",
    "    char_list = sum((df_sentences_filtered.loc[i:end_i].country_entities), [])\n",
    "\n",
    "    # Remove consecutive duplicates\n",
    "    char_unique = [char_list[i] for i in range(len(char_list)) if i == 0 or char_list[i] != char_list[i - 1]]\n",
    "\n",
    "    if len(char_unique) > 1:\n",
    "        for idx, a in enumerate(char_unique[:-1]):\n",
    "            b = char_unique[idx + 1]\n",
    "            relationships.append({\"source\": a, \"target\": b})\n",
    "\n",
    "# === Create & Aggregate Relationship DataFrame ===\n",
    "relationship_df = pd.DataFrame(relationships)\n",
    "relationship_df = pd.DataFrame(\n",
    "    np.sort(relationship_df.values, axis=1),\n",
    "    columns=[\"source\", \"target\"]\n",
    ")\n",
    "\n",
    "relationship_df[\"value\"] = 1\n",
    "relationship_df = relationship_df.groupby([\"source\", \"target\"], as_index=False).sum()\n",
    "\n",
    "# === Export to CSV ===\n",
    "relationship_df.to_csv(\"20th_century_country_relationships.csv\", index=False)\n",
    "\n",
    "# === Optional: Preview Data ===\n",
    "print(relationship_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "613daa40-9fb5-41ec-b03a-0d8ad79fe560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences_filtered.loc[:, \"country_entities\"] = df_sentences_filtered[\"country_entities\"].apply(\n",
    "    lambda x: [ent.split()[-1] for ent in x]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94524be-9a1e-4729-9b2b-aa686812a348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (20th_century)",
   "language": "python",
   "name": "20th_century"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
